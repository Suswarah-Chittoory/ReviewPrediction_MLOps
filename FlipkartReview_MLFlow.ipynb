{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Kfk4JRoLtRdJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import regex as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "1MbsZAchyNPm"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Suswarah\\Downloads\\MLOps\\MLFlow\\badminton_review_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust 칙?췇620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust 칙?췇620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Reviewer Name', 'Review Title', 'Place of Review', 'Up Votes',\n",
       "       'Down Votes', 'Month', 'Review text', 'Ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name       10\n",
       "Review Title        10\n",
       "Place of Review     50\n",
       "Up Votes            10\n",
       "Down Votes          10\n",
       "Month              465\n",
       "Review text          8\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(\"\", pd.NA, inplace = True)\n",
    "df.replace(\" \", pd.NA, inplace = True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "BlQVsNE2bQI1"
   },
   "outputs": [],
   "source": [
    "df.drop(['Reviewer Name', 'Place of Review', 'Up Votes', 'Down Votes', 'Month'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8518, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ly_Rcy_-ueYg",
    "outputId": "01250a8c-eea5-45df-842a-40cb556f5a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review Title    10\n",
       "Review text      8\n",
       "Ratings          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(\"\", pd.NA, inplace = True)\n",
    "df.replace(\" \", pd.NA, inplace = True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ot20GuqYdmkO",
    "outputId": "c37b8723-d381-46cc-e4c6-d9dbd10e884a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review Title    2\n",
       "Review text     0\n",
       "Ratings         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where both 'Review text' and 'Review Title' are null\n",
    "df.dropna(subset=['Review text', 'Review Title'], how='all', inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEcmAfUNpm2B",
    "outputId": "36c8b9a7-ef41-40da-bc7c-1ffa8584b68e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review Title    0\n",
       "Review text     0\n",
       "Ratings         0\n",
       "Sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review Title'].replace(pd.NA, \"None\", inplace = True)\n",
    "df['Review text'] = df['Review text'].str.replace(r'READ MORE', '', regex=True)\n",
    "# Use replace() with if condition to create the target variable 'Sentiment'\n",
    "df['Sentiment'] = df['Ratings'].replace({rating: 1 if rating >= 3 else 0 for rating in df['Ratings']})\n",
    "df.head()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8510, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "o3GNhUTDU13e",
    "outputId": "cb99998f-2bcb-4694-a956-cac3a6ba8e4e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Nice product Nice product, good quality, but p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't waste your money They didn't supplied Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Did not meet expectations Worst product. Damag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Fair Quite O. K. , but nowadays  the quality o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Over priced Over pricedJust 칙?췇620 ..from reta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                             Review\n",
       "0          1  Nice product Nice product, good quality, but p...\n",
       "1          0  Don't waste your money They didn't supplied Yo...\n",
       "2          0  Did not meet expectations Worst product. Damag...\n",
       "3          1  Fair Quite O. K. , but nowadays  the quality o...\n",
       "4          0  Over priced Over pricedJust 칙?췇620 ..from reta..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification\n",
    "df[\"Review\"] = df['Review Title'] + \" \" + df['Review text']\n",
    "df.drop(['Review Title', 'Review text', 'Ratings'], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "baTclFRFLbs_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPlA_Jqjax2W",
    "outputId": "42ca2fac-23d5-4f69-f7a2-e29f57257921"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "# Downloading wordnet before applying Lemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "0tp4e2kuUVGu"
   },
   "outputs": [],
   "source": [
    "y = df['Sentiment']\n",
    "x = df['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "09QuyKbhZ_tt"
   },
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItkrMnn2BYyP",
    "outputId": "cc025dbe-a023-4de8-f2b5-110bc811d941"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6808,), (1702,), (8510, 2), (6808,), (1702,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, df.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1372                                 Brilliant Very good.\n",
       "3846    Must buy! Have been purchasing the shuttles fr...\n",
       "333                    Highly recommended Nice product. .\n",
       "1259    Terrible product Worst on recent times.We play...\n",
       "3532                         Mind-blowing purchase Better\n",
       "                              ...                        \n",
       "5734                Pretty good genuine & orginal product\n",
       "5191             Delightful Badminton shuttle is too good\n",
       "5390                     Wonderful best quality shuttle 游둯\n",
       "860                         Highly recommended Nice happy\n",
       "7270                          Classy product Good product\n",
       "Name: Review, Length: 6808, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/Suswarah/Downloads/MLOps/MLFlow/mlruns/884060392742436811', creation_time=1711191325036, experiment_id='884060392742436811', last_update_time=1711191325036, lifecycle_stage='active', name='FlipkartReview_prediction', tags={}>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"FlipkartReview_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6808,), (6808,), (1702,), (1702,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4392                            awesome good\n",
       "8424    simply awesome good original product\n",
       "2138             classy product good quality\n",
       "3538                            awesome good\n",
       "2684                 could way better thanks\n",
       "Name: clean_review_lemma, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4392                            awesome good\n",
       "8424    simply awesome good original product\n",
       "2138             classy product good quality\n",
       "3538                            awesome good\n",
       "2684                 could way better thanks\n",
       "Name: clean_review_lemma, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Define text preprocessing function\n",
    "def preprocessor(text):\n",
    "    # Removing special characters and digits\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # change sentence to lower case\n",
    "    letters_only = letters_only.lower()\n",
    "    # tokenize into words\n",
    "    words = letters_only.split()\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Create pipelines for all models\n",
    "pipelines = {\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', TfidfVectorizer(preprocessor=preprocessor)),\n",
    "        ('classifier', LogisticRegression(max_iter=5000))\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('vectorization', TfidfVectorizer(preprocessor=preprocessor)),\n",
    "        ('classifier', SVC())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grids for all models\n",
    "param_grids = {\n",
    "    'logistic_regression': {\n",
    "        'vectorization__max_features': [1000, 1500, 2000],\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l2']\n",
    "    },\n",
    "    'SVC' : {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10],  # Regularization parameter\n",
    "        'classifier__kernel': ['linear', 'rbf', 'sigmoid'],  # Kernel type\n",
    "        'classifier__gamma': ['scale', 'auto']  # Kernel coefficient (for rbf, poly, sigmoid)\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- logistic_regression ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 11:38:48 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: total: 12.6 s\n",
      "Wall time: 31.1 s\n",
      "Train Score:  0.7333333333333333\n",
      "Test Score:  0.3333333333333333\n",
      "\n",
      "---------- SVC ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 11:39:20 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "CPU times: total: 14.5 s\n",
      "Wall time: 40.7 s\n",
      "Train Score:  0.7333333333333333\n",
      "Test Score:  0.3333333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "# Run the Pipeline\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(\"-\" * 10, model_name, \"-\" * 10)\n",
    "    grid_search = GridSearchCV(estimator=pipeline,\n",
    "                               param_grid=param_grids[model_name],\n",
    "                               scoring='f1_weighted',\n",
    "                               cv=5,\n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                               )\n",
    "    \n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(x_train, y_train)\n",
    "        \n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(x_test, y_test))\n",
    "    \n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 13:36:53 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '7ad0d59092ae463da9f726d46ef710b4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/24 13:36:53 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- logistic_regression ----------\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 14:29:53 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under file:///C:/Users/Suswarah/Downloads/MLOps/MLFlow/mlruns/884060392742436811/7ad0d59092ae463da9f726d46ef710b4/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2024/03/24 14:29:59 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under file:///C:/Users/Suswarah/Downloads/MLOps/MLFlow/mlruns/884060392742436811/7ad0d59092ae463da9f726d46ef710b4/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2024/03/24 14:30:02 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The run 7ad0d59092ae463da9f726d46ef710b4 must be in 'active' lifecycle_stage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9084859713112505\n",
      "Test Score:  0.9125609189924552\n",
      "Fit Time:  3189.569856405258\n",
      "Predict Time:  6.048084259033203\n",
      "Model Size:  106561\n",
      "---------- SVC ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 14:30:27 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e32dd9ecc4484301818ce20ce8bf0006', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2024/03/24 14:30:27 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/24 15:26:42 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9056792395725901\n",
      "Test Score:  0.9102225686431268\n",
      "Fit Time:  3369.839942216873\n",
      "Predict Time:  5.240501403808594\n",
      "Model Size:  261261\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for all models\n",
    "dev = 'Suswarah'\n",
    "best_models = {}\n",
    "\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(\"-\" * 10, model_name, \"-\" * 10)\n",
    "    grid_search = GridSearchCV(estimator=pipeline,\n",
    "                               param_grid=param_grids[model_name],\n",
    "                               scoring='f1_weighted',\n",
    "                               cv=5,\n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                               )\n",
    "#     mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    # Fit\n",
    "    start_fit_time = time.time()\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    end_fit_time = time.time()\n",
    "\n",
    "    # Predict\n",
    "    start_predict_time = time.time()\n",
    "    y_pred = grid_search.predict(x_test)\n",
    "    end_predict_time = time.time()\n",
    "\n",
    "    # Saving the best model\n",
    "    joblib.dump(grid_search.best_estimator_, f'best_models/{model_name}.pkl')\n",
    "    model_size = os.path.getsize(f'best_models/{model_name}.pkl')\n",
    "\n",
    "    # Pring Log\n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(x_test, y_test))\n",
    "    print(\"Fit Time: \", end_fit_time - start_fit_time)\n",
    "    print(\"Predict Time: \", end_predict_time - start_predict_time)\n",
    "    print(\"Model Size: \", model_size)\n",
    "    \n",
    "    # Start the experiment run\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log tags with mlflow.set_tag()\n",
    "        mlflow.set_tag(\"developer\", dev)\n",
    "\n",
    "        # Log Parameters with mlflow.log_param()\n",
    "        mlflow.log_param(\"algorithm\", model_name)\n",
    "        mlflow.log_param(\"hyperparameter_grid\", param_grids[model_name])\n",
    "        mlflow.log_param(\"best_hyperparameter\", grid_search.best_params_)\n",
    "\n",
    "        # Log Metrics with mlflow.log_metric()\n",
    "        mlflow.log_metric(\"train_score\", grid_search.best_score_)\n",
    "        mlflow.log_metric(\"test_score\", grid_search.score(x_test, y_test))\n",
    "        mlflow.log_metric(\"fit_time\", end_fit_time - start_fit_time)\n",
    "        mlflow.log_metric(\"predict_time\", end_predict_time - start_predict_time)\n",
    "        mlflow.log_metric(\"model_size\", model_size)\n",
    "\n",
    "        # Log Model using mlflow.sklearn.log_model()\n",
    "        mlflow.sklearn.log_model(grid_search.best_estimator_, f\"{model_name}_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Model**: Logistic Regression\n",
    "\n",
    "**Parameters**:\n",
    "        \n",
    "        'vectorization__max_features': 2000,\n",
    "        'classifier__C': 10,\n",
    "        'classifier__penalty': l2\n",
    "        \n",
    "**Accuracy**: 92%\n",
    "\n",
    "**F1 - score Positive Review Prediction** : 96%\n",
    "\n",
    "**F1 - score Negative Review Prediction** : 62%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2Byd5lc40wzh"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
