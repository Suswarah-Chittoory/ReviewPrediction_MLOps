{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kfk4JRoLtRdJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "baTclFRFLbs_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPlA_Jqjax2W",
    "outputId": "42ca2fac-23d5-4f69-f7a2-e29f57257921"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "# Downloading wordnet before applying Lemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1MbsZAchyNPm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file_path):\n",
    "    return pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nulls(df):\n",
    "    df.replace(\"\", pd.NA, inplace = True)\n",
    "    df.replace(\" \", pd.NA, inplace = True)\n",
    "    df.dropna(subset=['Review text', 'Review Title'], how='all', inplace=True)\n",
    "    df['Review Title'].replace(pd.NA, \"None\", inplace = True)\n",
    "    df.isnull().sum()\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BlQVsNE2bQI1"
   },
   "outputs": [],
   "source": [
    "def feature_extraction(df):\n",
    "    df.drop(['Reviewer Name', 'Place of Review', 'Up Votes', 'Down Votes', 'Month'], axis=1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEcmAfUNpm2B",
    "outputId": "36c8b9a7-ef41-40da-bc7c-1ffa8584b68e"
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['Review text'] = df['Review text'].str.replace(r'READ MORE', '', regex=True)\n",
    "    # Use replace() with if condition to create the target variable 'Sentiment'\n",
    "    df['Sentiment'] = df['Ratings'].replace({rating: 1 if rating >= 3 else 0 for rating in df['Ratings']})\n",
    "    df[\"Review\"] = df['Review Title'] + \" \" + df['Review text']\n",
    "    df.drop(['Review Title', 'Review text', 'Ratings'], axis = 1, inplace = True)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inputs_output(data, inputs, output):\n",
    "    \n",
    "    x = data[inputs]\n",
    "    y = data[output]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(x, y, test_size=0.25, random_state=0):\n",
    "    \n",
    "    return train_test_split(x, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    # Removing special characters and digits\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # change sentence to lower case\n",
    "    letters_only = letters_only.lower()\n",
    "    # tokenize into words\n",
    "    words = letters_only.split()\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    # Define TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessor)\n",
    "\n",
    "    # Fit TF-IDF vectorizer on X_train and transform X_train and X_test\n",
    "    x_train_transformed = tfidf_vectorizer.fit_transform(X_train)\n",
    "    x_test_transformed = tfidf_vectorizer.transform(X_test)\n",
    " \n",
    "    return x_train_transformed, x_test_transformed, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train_transformed, y_train, hyperparameters):\n",
    "\n",
    "    clf = LogisticRegression(**hyperparameters)\n",
    "    clf.fit(x_train_transformed, y_train)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train_transformed, y_train, x_test_transformed, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(x_train_transformed)\n",
    "    y_test_pred = model.predict(x_test_transformed)\n",
    "\n",
    "    train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    test_score = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Model**: Logistic Regression\n",
    "\n",
    "**Parameters**:\n",
    "        \n",
    "        'vectorization__max_features': 2000,\n",
    "        'classifier__C': 10,\n",
    "        'classifier__penalty': l2\n",
    "        \n",
    "**Accuracy**: 92%\n",
    "\n",
    "**F1 - score Positive Review Prediction** : 96%\n",
    "\n",
    "**F1 - score Negative Review Prediction** : 62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workflow(data_path):\n",
    "    DATA_PATH = data_path\n",
    "    INPUTS = 'Review'\n",
    "    OUTPUT = 'Sentiment'\n",
    "    HYPERPARAMETERS = {'C': 10, 'max_iter': 5000, 'penalty': 'l2'}\n",
    "\n",
    "\n",
    "    # Load data\n",
    "    df = import_data(DATA_PATH)\n",
    "    \n",
    "    # Handle nulls\n",
    "    df = handle_nulls(df)\n",
    "    \n",
    "    # Extract Features\n",
    "    df = feature_extraction(df)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df = feature_engineering(df)\n",
    "    print(\"Nulls in data:\\n\",df.isnull().sum())\n",
    "\n",
    "    \n",
    "    # Identify Inputs and Output\n",
    "    x, y = split_inputs_output(df, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    x_train, x_test, y_train, y_test = split_train_test(x, y)\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    x_train_transformed, x_test_transformed, y_train, y_test = preprocess_data(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(x_train_transformed, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, x_train_transformed, y_train, x_test_transformed, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls in data:\n",
      " Sentiment    0\n",
      "Review       0\n",
      "dtype: int64\n",
      "(7,) (3,) (7,) (3,)\n",
      "Train Score: 1.0\n",
      "Test Score: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow(data_path=\"C:\\\\Users\\\\Suswarah\\\\Downloads\\\\MLOps\\\\MLFlow\\\\badminton_review_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def import_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "@task\n",
    "def handle_nulls(df):\n",
    "    df.replace(\"\", pd.NA, inplace = True)\n",
    "    df.replace(\" \", pd.NA, inplace = True)\n",
    "    df.dropna(subset=['Review text', 'Review Title'], how='all', inplace=True)\n",
    "    df['Review Title'].replace(pd.NA, \"None\", inplace = True)\n",
    "    df.isnull().sum()\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "@task\n",
    "def feature_extraction(df):\n",
    "    df.drop(['Reviewer Name', 'Place of Review', 'Up Votes', 'Down Votes', 'Month'], axis=1, inplace = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "@task\n",
    "def feature_engineering(df):\n",
    "    df['Review text'] = df['Review text'].str.replace(r'READ MORE', '', regex=True)\n",
    "    # Use replace() with if condition to create the target variable 'Sentiment'\n",
    "    df['Sentiment'] = df['Ratings'].replace({rating: 1 if rating >= 3 else 0 for rating in df['Ratings']})\n",
    "    df[\"Review\"] = df['Review Title'] + \" \" + df['Review text']\n",
    "    df.drop(['Review Title', 'Review text', 'Ratings'], axis = 1, inplace = True)\n",
    "    df.head()\n",
    "    return df\n",
    "\n",
    "\n",
    "@task\n",
    "def split_inputs_output(data, inputs, output):\n",
    "    \n",
    "    x = data[inputs]\n",
    "    y = data[output]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "@task\n",
    "def split_train_test(x, y, test_size=0.25, random_state=0):\n",
    "    \n",
    "    return train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@task\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    def preprocessor(text):\n",
    "        # Removing special characters and digits\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        # change sentence to lower case\n",
    "        letters_only = letters_only.lower()\n",
    "        # tokenize into words\n",
    "        words = letters_only.split()\n",
    "        # remove stop words\n",
    "        words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "        # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    # Define TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessor)\n",
    "\n",
    "    # Fit TF-IDF vectorizer on X_train and transform X_train and X_test\n",
    "    x_train_transformed = tfidf_vectorizer.fit_transform(X_train)\n",
    "    x_test_transformed = tfidf_vectorizer.transform(X_test)\n",
    "    return x_train_transformed, x_test_transformed, y_train, y_test\n",
    "\n",
    "\n",
    "@task\n",
    "def train_model(x_train_transformed, y_train, hyperparameters):\n",
    "\n",
    "    clf = LogisticRegression(**hyperparameters)\n",
    "    clf.fit(x_train_transformed, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "\n",
    "@task\n",
    "def evaluate_model(model, x_train_transformed, y_train, x_test_transformed, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(x_train_transformed)\n",
    "    y_test_pred = model.predict(x_test_transformed)\n",
    "\n",
    "    train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    test_score = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow(name=\"Logistic Regression final Flow\")\n",
    "def workflow():\n",
    "    DATA_PATH = \"C:\\\\Users\\\\Suswarah\\\\Downloads\\\\MLOps\\\\MLFlow\\\\badminton_review_data.csv\"\n",
    "    INPUTS = 'Review'\n",
    "    OUTPUT = 'Sentiment'\n",
    "    HYPERPARAMETERS = {'C': 10, 'max_iter': 5000, 'penalty': 'l2'}\n",
    "\n",
    "\n",
    "    # Load data\n",
    "    df = import_data(DATA_PATH)\n",
    "    \n",
    "    # Handle nulls\n",
    "    df = handle_nulls(df)\n",
    "    \n",
    "    # Extract Features\n",
    "    df = feature_extraction(df)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df = feature_engineering(df)\n",
    "\n",
    "    \n",
    "    # Identify Inputs and Output\n",
    "    x, y = split_inputs_output(df, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    x_train, x_test, y_train, y_test = split_train_test(x, y)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    x_train_transformed, x_test_transformed, y_train, y_test = preprocess_data(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    # Build a model\n",
    "    model = train_model(x_train_transformed, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, x_train_transformed, y_train, x_test_transformed, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:45.701 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Logistic Regression final Flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:45.701 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'futuristic-shark'\u001b[0m for flow\u001b[1;35m 'Logistic Regression final Flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:45.983 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'import_data-0' for task 'import_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:45.983 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'import_data-0' for task 'import_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:45.983 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'import_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:45.983 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'import_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:46.374 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'import_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:46.374 | \u001b[36mINFO\u001b[0m    | Task run 'import_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:46.482 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'handle_nulls-0' for task 'handle_nulls'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:46.482 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'handle_nulls-0' for task 'handle_nulls'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:46.501 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'handle_nulls-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:46.501 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'handle_nulls-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:46.824 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'handle_nulls-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:46.824 | \u001b[36mINFO\u001b[0m    | Task run 'handle_nulls-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:46.937 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'feature_extraction-0' for task 'feature_extraction'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:46.937 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'feature_extraction-0' for task 'feature_extraction'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:46.937 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'feature_extraction-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:46.937 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'feature_extraction-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:47.273 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'feature_extraction-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:47.273 | \u001b[36mINFO\u001b[0m    | Task run 'feature_extraction-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:47.409 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'feature_engineering-0' for task 'feature_engineering'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:47.409 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'feature_engineering-0' for task 'feature_engineering'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:47.409 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'feature_engineering-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:47.409 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'feature_engineering-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:47.717 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'feature_engineering-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:47.717 | \u001b[36mINFO\u001b[0m    | Task run 'feature_engineering-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:47.837 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:47.837 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:47.837 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'split_inputs_output-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:47.837 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'split_inputs_output-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:48.264 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_inputs_output-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:48.264 | \u001b[36mINFO\u001b[0m    | Task run 'split_inputs_output-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:48.415 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'split_train_test-0' for task 'split_train_test'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:48.415 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'split_train_test-0' for task 'split_train_test'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:48.419 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'split_train_test-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:48.419 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'split_train_test-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:48.759 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_train_test-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:48.759 | \u001b[36mINFO\u001b[0m    | Task run 'split_train_test-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:48.875 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'preprocess_data-0' for task 'preprocess_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:48.875 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'preprocess_data-0' for task 'preprocess_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:33:48.875 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'preprocess_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:33:48.875 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'preprocess_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:11.580 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:11.580 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:11.687 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'train_model-0' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:11.687 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'train_model-0' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:11.687 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'train_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:11.687 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'train_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:12.175 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:12.175 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:12.300 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Created task run 'evaluate_model-0' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:12.300 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Created task run 'evaluate_model-0' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:12.313 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Executing 'evaluate_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:12.313 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Executing 'evaluate_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:12.662 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:12.662 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9550297712315888\n",
      "Test Score: 0.9144736842105263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:34:12.813 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'futuristic-shark'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:34:12.813 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'futuristic-shark'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     workflow.serve(\n",
    "#         name=\"my-first-deployment\",\n",
    "#         cron=\"* * * * *\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Suswarah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'import_data' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:31' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'handle_nulls' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:36' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'feature_extraction' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:47' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'feature_engineering' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:53' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'split_inputs_output' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:64' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'split_train_test' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:72' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'preprocess_data' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:80' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'train_model' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:105' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\tasks.py:348: UserWarning: A task named 'evaluate_model' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:114' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\anaconda3\\Lib\\site-packages\\prefect\\flows.py:357: UserWarning: A flow named 'Logistic Regression final Flow' and defined at 'C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:130' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n",
      "\n",
      " `@flow(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "C:\\Users\\Suswarah\\Downloads\\MLOps\\Orchestrate_Models\\FlipkartReviewCron.py:172: RuntimeWarning: coroutine 'Flow.serve' was never awaited\n",
      "  workflow.serve(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "%run FlipkartReviewCron.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2Byd5lc40wzh"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
